# Tuner-Vs.-SIREN-architecture-Comparison-Study-
My research study I conducted comparing TUNER vs. SIREN architecture and initialization for sinusoidal neural networks under the guidance of Proff. Tiago Novello and Luiz Velho from Instituto Nacional de Matemática Pura e Aplicada. Original full paper (from Proff. Luiz Velho and Tiago Novello) : https://arxiv.org/pdf/2407.21121 

Hello! I’m **Yanet Tesfaye**, a high school student passionate about computer science, AI, and applied mathematics. I had the opportunity to **participate in a research study comparing SIREN vs TUNER initialization methods** for sinusoidal neural networks, under the guidance of Professors Tiago Novello & Luiz Velho from IMPA.

The Google Slides presentation included in this repository was created to showcase my active contributions to the research study comparing SIREN and TUNER initialization methods for sinusoidal neural networks.

 I participated in the project by analyzing the methodology, preparing visualizations, and summarizing preliminary results, and the slides serve as a professional record of my engagement and understanding of the subject matter.

The presentation begins with an introduction to sinusoidal neural networks, where I explained the significance of initialization for training stability and effective spectral representation. I then outlined the research goals and motivation, providing context for why comparing SIREN and TUNER is important for improving neural network performance.

Next, I dedicated slides to explaining the SIREN and TUNER initialization methods. I described how SIREN uses randomly sampled input frequencies and how TUNER uses structured, discrete frequency sampling. o enhance clarity, I created visual diagrams and charts illustrating frequency distributions, highlighting the differences between random and structured initialization, and demonstrating how each method impacts network behavior.

I also included notes on limitations and areas for further investigation, reflecting my critical engagement with the research.
Finally, the presentation concludes with future directions and insights, highlighting potential extensions of the study, such as exploring multi-resolution networks and real-world applications in signal reconstruction and medical data modeling. Throughout the slides, I ensured that my interpretation of the results and visual summaries clearly communicated both the technical aspects of the study and my analytical contributions.

Overall, this presentation demonstrates not only my understanding of neural implicit representations and initialization strategies, but also my ability to actively contribute to a research project, analyze results, and communicate complex scientific concepts in a clear, professional format.
